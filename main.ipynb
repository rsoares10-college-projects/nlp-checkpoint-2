{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk import SnowballStemmer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from unidecode import unidecode\n",
    "import json\n",
    "import string\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obtenção dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/prof-renato/data/main/humor_detection.csv')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratando textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importando um JSON com uma lista de palavras a serem substituidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('contraction_map.json') as file:\n",
    "    contration_map = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(list_tokens, stemmer):\n",
    "    return [stemmer.stem(token) for token in list_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeWords(listTokens, listWords):\n",
    "    return [token for token in listTokens if token not in listWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contration_words(text):\n",
    "    for k, v in contration_map.items():\n",
    "        text = text.replace(k, v)\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textProcess(text):\n",
    "    stopWords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "    text = text.replace(u'\\ufffd', '8')\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.rstrip('\\n')\n",
    "    text = contration_words(text)\n",
    "\n",
    "    listTokens = word_tokenize(text)\n",
    "    listTokens= removeWords(listTokens, stopWords)\n",
    "\n",
    "    text = \" \".join(listTokens)\n",
    "    text = unidecode(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_pipe = Pipeline([\n",
    "    ('CountVectorizer', CountVectorizer(analyzer=textProcess)),\n",
    "    ('TDFID', TfidfTransformer()),\n",
    "    ('RandomForest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "multinomialNB_pipe = Pipeline([\n",
    "    ('CountVectorizer', CountVectorizer(analyzer=textProcess)),\n",
    "    ('TDFID', TfidfTransformer()),\n",
    "    ('RandomForest', MultinomialNB())\n",
    "])\n",
    "\n",
    "logistic_regression_pipe = Pipeline([\n",
    "    ('CountVectorizer', CountVectorizer(analyzer=textProcess)),\n",
    "    ('TDFID', TfidfTransformer()),\n",
    "    ('RandomForest', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['humor'] = pd.to_numeric(df['humor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['humor']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utilizando o cross validantion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model = cross_validate(logistic_regression_pipe, X, y, scoring=['accuracy', 'f1', 'roc_auc'], return_train_score=True)\n",
    "random_forest_model = cross_validate(random_forest_pipe, X, y, scoring=['accuracy', 'f1', 'roc_auc'], return_train_score=True)\n",
    "multinomialnb_model = cross_validate(multinomialNB_pipe, X, y, scoring=['accuracy', 'f1', 'roc_auc'], return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5164a_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >accuracy</th>\n",
       "      <th class=\"col_heading level0 col1\" >f1</th>\n",
       "      <th class=\"col_heading level0 col2\" >roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5164a_level0_row0\" class=\"row_heading level0 row0\" >logistic</th>\n",
       "      <td id=\"T_5164a_row0_col0\" class=\"data row0 col0\" >0.792316</td>\n",
       "      <td id=\"T_5164a_row0_col1\" class=\"data row0 col1\" >0.781166</td>\n",
       "      <td id=\"T_5164a_row0_col2\" class=\"data row0 col2\" >0.861245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5164a_level0_row1\" class=\"row_heading level0 row1\" >random_forest</th>\n",
       "      <td id=\"T_5164a_row1_col0\" class=\"data row1 col0\" >0.809518</td>\n",
       "      <td id=\"T_5164a_row1_col1\" class=\"data row1 col1\" >0.798332</td>\n",
       "      <td id=\"T_5164a_row1_col2\" class=\"data row1 col2\" >0.882209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5164a_level0_row2\" class=\"row_heading level0 row2\" >multinomialNB_forest</th>\n",
       "      <td id=\"T_5164a_row2_col0\" class=\"data row2 col0\" >0.760297</td>\n",
       "      <td id=\"T_5164a_row2_col1\" class=\"data row2 col1\" >0.746542</td>\n",
       "      <td id=\"T_5164a_row2_col2\" class=\"data row2 col2\" >0.814479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2440e9ef0d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = pd.DataFrame({\n",
    "    'labels': ['accuracy', 'f1', 'roc_auc'],\n",
    "    'logistic': [logistic_regression_model['test_accuracy'].max(), logistic_regression_model['test_f1'].max(), logistic_regression_model['test_roc_auc'].max()],\n",
    "    'random_forest': [random_forest_model['test_accuracy'].max(), random_forest_model['test_f1'].max(), random_forest_model['test_roc_auc'].max()],\n",
    "    'multinomialNB_forest': [multinomialnb_model['test_accuracy'].max(), multinomialnb_model['test_f1'].max(), multinomialnb_model['test_roc_auc'].max()]\n",
    "}).set_index('labels')\n",
    "resultado.index.name=None\n",
    "resultado = resultado.transpose()    \n",
    "resultado.style.applymap(lambda x: 'background-color: lightgreen' if x >= 0.90 else '')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
